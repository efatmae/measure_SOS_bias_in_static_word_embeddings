{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1377ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2885ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_of_words_in_df(df, slur_list, text_col):\n",
    "  ps_in_hateEval = []\n",
    "  for i in slur_list: \n",
    "    if  df[text_col].str.contains(i).any() == True:\n",
    "      print(\"terms found \"+ i)  \n",
    "      ps_mid = df[df[text_col].str.contains(i)]\n",
    "      ps_in_hateEval.append(ps_mid)\n",
    "      \n",
    "  if len(ps_in_hateEval)>0:\n",
    "      ps_in_hateEval_df = pd.concat(ps_in_hateEval)\n",
    "      return ps_in_hateEval_df\n",
    "  else:\n",
    "        print (\"Nothing found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b45ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e0b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_words = open(data_folder+\"swear_words.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77e9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_folder = \"./collocation_results_1M_reddit/minority/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8125a890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reddit_transgender_collocation.csv',\n",
       " 'reddit_tran_collocation.csv',\n",
       " 'reddit_lesbian_collocation.csv',\n",
       " 'reddit_mother_collocation.csv',\n",
       " 'reddit_wife_collocation.csv',\n",
       " 'reddit_daughter_collocation.csv',\n",
       " 'reddit_bisexual_collocation.csv',\n",
       " 'reddit_arab_collocation.csv',\n",
       " 'reddit_sister_collocation.csv',\n",
       " 'reddit_woman_collocation.csv',\n",
       " 'reddit_gay_collocation.csv',\n",
       " 'reddit_african_collocation.csv',\n",
       " 'reddit_mexican_collocation.csv',\n",
       " 'reddit_girl_collocation.csv',\n",
       " 'reddit_asian_collocation.csv',\n",
       " 'reddit_hispanic_collocation.csv',\n",
       " 'reddit_lgbt_collocation.csv',\n",
       " 'reddit_homosexual_collocation.csv',\n",
       " 'reddit_queer_collocation.csv',\n",
       " 'reddit_female_collocation.csv',\n",
       " 'reddit_black_collocation.csv',\n",
       " 'reddit_lgbtq_collocation.csv',\n",
       " 'reddit_indian_collocation.csv',\n",
       " 'reddit_latin_collocation.csv',\n",
       " 'reddit_non-binary_collocation.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(collocation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449d2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_transgender_collocation = pd.read_csv(collocation_folder+\"/reddit_transgender_collocation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb105228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_transgender_collocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a81409e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'word1', 'word2', 'PMI'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_transgender_collocation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a8c68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found sex\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_transgender_collocation_insults1 = find_list_of_words_in_df(reddit_transgender_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_transgender_collocation_insults2 = find_list_of_words_in_df(reddit_transgender_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_transgender_collocation_insults = pd.concat([reddit_transgender_collocation_insults1,reddit_transgender_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923a2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transgender insultive collocation average PMI: 13.360590281903448\n"
     ]
    }
   ],
   "source": [
    "print(\"transgender insultive collocation average PMI:\",np.mean(reddit_transgender_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2fe2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_lgbtq_collocation = pd.read_csv(collocation_folder+\"/reddit_lgbtq_collocation.csv\")\n",
    "reddit_lgbtq_collocation_insults1 = find_list_of_words_in_df(reddit_lgbtq_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lgbtq_collocation_insults2 = find_list_of_words_in_df(reddit_lgbtq_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_lgbtq_collocation_insults = pd.concat([reddit_lgbtq_collocation_insults1,reddit_lgbtq_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a978867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bitch\n",
      "terms found cum\n",
      "terms found cums\n",
      "terms found sex\n",
      "terms found mean\n",
      "terms found nazi\n",
      "terms found sex\n",
      "terms found shi\n"
     ]
    }
   ],
   "source": [
    "reddit_lesbian_collocation = pd.read_csv(collocation_folder+\"/reddit_lesbian_collocation.csv\")\n",
    "reddit_lesbian_collocation_insults1 = find_list_of_words_in_df(reddit_lesbian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lesbian_collocation_insults2 = find_list_of_words_in_df(reddit_lesbian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_lesbian_collocation_insults = pd.concat([reddit_lesbian_collocation_insults1,reddit_lesbian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3d33500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesbian insultive collocation average PMI: 7.572735992049391\n"
     ]
    }
   ],
   "source": [
    "print(\"lesbian insultive collocation average PMI:\",np.mean(reddit_lesbian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281fe26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found bitch\n",
      "terms found cum\n",
      "terms found cunt\n",
      "terms found dick\n",
      "terms found dirty\n",
      "terms found dumb\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fucked\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found idiot\n",
      "terms found jap\n",
      "terms found kill\n",
      "terms found punch\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found sob\n",
      "terms found stupid\n",
      "terms found suck\n",
      "terms found twat\n",
      "terms found ugly\n",
      "terms found anal\n",
      "terms found ass\n",
      "terms found bad\n",
      "terms found balls\n",
      "terms found bitch\n",
      "terms found cunt\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fucked\n",
      "terms found fucker\n",
      "terms found fuckers\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found jerk\n",
      "terms found kick\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found mf\n",
      "terms found mfo\n",
      "terms found punch\n",
      "terms found shi\n",
      "terms found slap\n",
      "terms found spac\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_mother_collocation = pd.read_csv(collocation_folder+\"/reddit_mother_collocation.csv\")\n",
    "reddit_mother_collocation_insults1 = find_list_of_words_in_df(reddit_mother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_mother_collocation_insults2 = find_list_of_words_in_df(reddit_mother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_mother_collocation_insults = pd.concat([reddit_mother_collocation_insults1,reddit_mother_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aba064ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother insultive collocation average PMI: 5.255479565638343\n"
     ]
    }
   ],
   "source": [
    "print(\"mother insultive collocation average PMI:\",np.mean(reddit_mother_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1801c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found bitch\n",
      "terms found butt\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found idiot\n",
      "terms found jap\n",
      "terms found nazi\n",
      "terms found sex\n",
      "terms found slut\n",
      "terms found stupid\n",
      "terms found ugly\n",
      "terms found anal\n",
      "terms found ass\n",
      "terms found cum\n",
      "terms found aps\n",
      "terms found fuck\n",
      "terms found fucked\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found kill\n",
      "terms found lick\n",
      "terms found mean\n",
      "terms found piss\n",
      "terms found pissed\n",
      "terms found piss\n",
      "terms found aps\n",
      "terms found prick\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found slap\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_wife_collocation = pd.read_csv(collocation_folder+\"/reddit_wife_collocation.csv\")\n",
    "reddit_wife_collocation_insults1 = find_list_of_words_in_df(reddit_wife_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_wife_collocation_insults2 = find_list_of_words_in_df(reddit_wife_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_wife_collocation_insults = pd.concat([reddit_wife_collocation_insults1,reddit_wife_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ce039f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wife insultive collocation average PMI: 2.343543802135451\n"
     ]
    }
   ],
   "source": [
    "print(\"wife insultive collocation average PMI:\",np.mean(reddit_wife_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5dce148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_trans_collocation = pd.read_csv(collocation_folder+\"/reddit_tran_collocation.csv\")\n",
    "reddit_trans_collocation_insults1 = find_list_of_words_in_df(reddit_trans_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_trans_collocation_insults2 = find_list_of_words_in_df(reddit_trans_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "#reddit_trans_collocation_insults = pd.concat([reddit_trans_collocation_insults1,reddit_trans_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3772a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bastard\n",
      "terms found hell\n",
      "terms found mean\n",
      "terms found ass\n",
      "terms found asses\n",
      "terms found cum\n",
      "terms found mean\n",
      "terms found pron\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_latino_collocation = pd.read_csv(collocation_folder+\"/reddit_latin_collocation.csv\")\n",
    "reddit_latino_collocation_insults1 = find_list_of_words_in_df(reddit_latino_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_latino_collocation_insults2 = find_list_of_words_in_df(reddit_latino_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_latino_collocation_insults = pd.concat([reddit_latino_collocation_insults1,reddit_latino_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0be6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin insultive collocation average PMI: 6.301463529326156\n"
     ]
    }
   ],
   "source": [
    "print(\"latin insultive collocation average PMI:\",np.mean(reddit_latino_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "190d24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found butt\n",
      "terms found cunt\n",
      "terms found cunts\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found homo\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found sht\n",
      "terms found slut\n",
      "terms found anal\n",
      "terms found boob\n",
      "terms found boobs\n",
      "terms found cum\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fucks\n",
      "terms found hate\n",
      "terms found kill\n",
      "terms found pron\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found sob\n"
     ]
    }
   ],
   "source": [
    "reddit_daughter_collocation = pd.read_csv(collocation_folder+\"/reddit_daughter_collocation.csv\")\n",
    "reddit_daughter_collocation_insults1 = find_list_of_words_in_df(reddit_daughter_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_daughter_collocation_insults2 = find_list_of_words_in_df(reddit_daughter_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_daughter_collocation_insults = pd.concat([reddit_daughter_collocation_insults1,reddit_daughter_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4943e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daughter insultive collocation average PMI: 5.240072941330608\n"
     ]
    }
   ],
   "source": [
    "print(\"daughter insultive collocation average PMI:\",np.mean(reddit_daughter_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f8d2aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found sex\n",
      "terms found fat\n",
      "terms found sex\n"
     ]
    }
   ],
   "source": [
    "reddit_bisexual_collocation = pd.read_csv(collocation_folder+\"/reddit_bisexual_collocation.csv\")\n",
    "reddit_bisexual_collocation_insults1 = find_list_of_words_in_df(reddit_bisexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_bisexual_collocation_insults2 = find_list_of_words_in_df(reddit_bisexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_bisexual_collocation_insults = pd.concat([reddit_bisexual_collocation_insults1,reddit_bisexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d8107ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bisexual insultive collocation average PMI: 6.389065104126114\n"
     ]
    }
   ],
   "source": [
    "print(\"bisexual insultive collocation average PMI:\",np.mean(reddit_bisexual_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0eb5bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found ass\n",
      "terms found butt\n",
      "terms found fuck\n",
      "terms found fucked\n",
      "terms found nigger\n",
      "terms found niggers\n",
      "terms found shi\n"
     ]
    }
   ],
   "source": [
    "reddit_arab_collocation = pd.read_csv(collocation_folder+\"/reddit_arab_collocation.csv\")\n",
    "reddit_arab_collocation_insults1 = find_list_of_words_in_df(reddit_arab_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_arab_collocation_insults2 = find_list_of_words_in_df(reddit_arab_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_arab_collocation_insults = pd.concat([reddit_arab_collocation_insults1,reddit_arab_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4061d77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arab insultive collocation average PMI: 7.267655800836713\n"
     ]
    }
   ],
   "source": [
    "print(\"arab insultive collocation average PMI:\",np.mean(reddit_arab_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d38fc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bitch\n",
      "terms found dirty\n",
      "terms found dumb\n",
      "terms found dumbass\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found retard\n",
      "terms found ugly\n",
      "terms found ass\n",
      "terms found fuck\n",
      "terms found fucker\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found fucks\n",
      "terms found hate\n",
      "terms found shi\n",
      "terms found shut\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_sister_collocation = pd.read_csv(collocation_folder+\"/reddit_sister_collocation.csv\")\n",
    "reddit_sister_collocation_insults1 = find_list_of_words_in_df(reddit_sister_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_sister_collocation_insults2 = find_list_of_words_in_df(reddit_sister_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_sister_collocation_insults = pd.concat([reddit_sister_collocation_insults1,reddit_sister_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2197636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister insultive collocation average PMI: 3.1405459994459997\n"
     ]
    }
   ],
   "source": [
    "print(\"sister insultive collocation average PMI:\",np.mean(reddit_sister_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bacb9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found asshole\n",
      "terms found bitch\n",
      "terms found cum\n",
      "terms found dumb\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fucka\n",
      "terms found fucked\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found jap\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found retard\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found skank\n",
      "terms found sob\n",
      "terms found stupid\n",
      "terms found tit\n",
      "terms found ugly\n",
      "terms found ass\n",
      "terms found bitch\n",
      "terms found bitchin\n",
      "terms found bitching\n",
      "terms found cum\n",
      "terms found cunt\n",
      "terms found aps\n",
      "terms found fuck\n",
      "terms found fucks\n",
      "terms found hate\n",
      "terms found jerk\n",
      "terms found kick\n",
      "terms found kill\n",
      "terms found lick\n",
      "terms found lust\n",
      "terms found mean\n",
      "terms found mf\n",
      "terms found orgasm\n",
      "terms found piss\n",
      "terms found pissed\n",
      "terms found piss\n",
      "terms found aps\n",
      "terms found poop\n",
      "terms found pron\n",
      "terms found punch\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shut\n",
      "terms found slap\n",
      "terms found stfu\n",
      "terms found stupid\n",
      "terms found suck\n",
      "terms found tit\n",
      "terms found titt\n",
      "terms found tittie\n",
      "terms found titties\n",
      "terms found ugly\n"
     ]
    }
   ],
   "source": [
    "reddit_woman_collocation = pd.read_csv(collocation_folder+\"/reddit_woman_collocation.csv\")\n",
    "reddit_woman_collocation_insults1 = find_list_of_words_in_df(reddit_woman_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_woman_collocation_insults2 = find_list_of_words_in_df(reddit_woman_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_woman_collocation_insults = pd.concat([reddit_woman_collocation_insults1,reddit_woman_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44cdb39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman insultive collocation average PMI: 4.286271039685767\n"
     ]
    }
   ],
   "source": [
    "print(\"woman insultive collocation average PMI:\",np.mean(reddit_woman_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8851593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found bitch\n",
      "terms found disgusting\n",
      "terms found aps\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found homo\n",
      "terms found kick\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found mf\n",
      "terms found mfo\n",
      "terms found motherfuck\n",
      "terms found motherfuckin\n",
      "terms found motherfucking\n",
      "terms found nigger\n",
      "terms found penis\n",
      "terms found aps\n",
      "terms found pron\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found stupid\n",
      "terms found tit\n",
      "terms found wse\n",
      "terms found anal\n",
      "terms found ass\n",
      "terms found asshole\n",
      "terms found assholes\n",
      "terms found butt\n",
      "terms found cock\n",
      "terms found cocks\n",
      "terms found cocksuck\n",
      "terms found cocksucking\n",
      "terms found fag\n",
      "terms found faggot\n",
      "terms found fags\n",
      "terms found aps\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found gangbang\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found homo\n",
      "terms found hore\n",
      "terms found jap\n",
      "terms found jiz\n",
      "terms found jizz\n",
      "terms found lick\n",
      "terms found mean\n",
      "terms found nigger\n",
      "terms found niggers\n",
      "terms found aps\n",
      "terms found pron\n",
      "terms found punch\n",
      "terms found pussy\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found suck\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_gay_collocation = pd.read_csv(collocation_folder+\"/reddit_gay_collocation.csv\")\n",
    "reddit_gay_collocation_insults1 = find_list_of_words_in_df(reddit_gay_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_gay_collocation_insults2 = find_list_of_words_in_df(reddit_gay_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_gay_collocation_insults = pd.concat([reddit_gay_collocation_insults1,reddit_gay_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40bed6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gay insultive collocation average PMI: 4.282484059757225\n"
     ]
    }
   ],
   "source": [
    "print(\"gay insultive collocation average PMI:\",np.mean(reddit_gay_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d3505b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found dirty\n",
      "terms found fat\n",
      "terms found pron\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_african_collocation = pd.read_csv(collocation_folder+\"/reddit_african_collocation.csv\")\n",
    "reddit_african_collocation_insults1 = find_list_of_words_in_df(reddit_african_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_african_collocation_insults2 = find_list_of_words_in_df(reddit_african_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_african_collocation_insults = pd.concat([reddit_african_collocation_insults1,reddit_african_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d944b839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "african insultive collocation average PMI: 6.080263287709646\n"
     ]
    }
   ],
   "source": [
    "print(\"african insultive collocation average PMI:\",np.mean(reddit_african_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7ab8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found dirty\n",
      "terms found dumb\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found ass\n",
      "terms found bad\n",
      "terms found cok\n",
      "terms found shi\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_mexican_collocation = pd.read_csv(collocation_folder+\"/reddit_mexican_collocation.csv\")\n",
    "reddit_mexican_collocation_insults1 = find_list_of_words_in_df(reddit_mexican_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_mexican_collocation_insults2 = find_list_of_words_in_df(reddit_mexican_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_mexican_collocation_insults = pd.concat([reddit_mexican_collocation_insults1,reddit_mexican_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87256060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mexican insultive collocation average PMI: 5.029471832555781\n"
     ]
    }
   ],
   "source": [
    "print(\"mexican insultive collocation average PMI:\",np.mean(reddit_mexican_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d66cbb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found fag\n",
      "terms found faggot\n",
      "terms found hate\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_lgtb_collocation = pd.read_csv(collocation_folder+\"/reddit_lgbt_collocation.csv\")\n",
    "reddit_lgtb_collocation_insults1 = find_list_of_words_in_df(reddit_lgtb_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lgtb_collocation_insults2 = find_list_of_words_in_df(reddit_lgtb_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_lgtb_collocation_insults = pd.concat([reddit_lgtb_collocation_insults1,reddit_lgtb_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a343f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbt insultive collocation average PMI: 8.051060031765687\n"
     ]
    }
   ],
   "source": [
    "print(\"lgbt insultive collocation average PMI:\",np.mean(reddit_lgtb_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97fc6b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found arse\n",
      "terms found ass\n",
      "terms found bad\n",
      "terms found bitch\n",
      "terms found butt\n",
      "terms found cock\n",
      "terms found dirty\n",
      "terms found dumb\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found hoar\n",
      "terms found hoe\n",
      "terms found hoes\n",
      "terms found hore\n",
      "terms found horniest\n",
      "terms found horny\n",
      "terms found idiot\n",
      "terms found jap\n",
      "terms found kick\n",
      "terms found labia\n",
      "terms found mean\n",
      "terms found poop\n",
      "terms found pube\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found smell\n",
      "terms found smelly\n",
      "terms found sob\n",
      "terms found stupid\n",
      "terms found tit\n",
      "terms found tits\n",
      "terms found ugly\n",
      "terms found ass\n",
      "terms found bitch\n",
      "terms found bitchin\n",
      "terms found bitching\n",
      "terms found blowjob\n",
      "terms found butt\n",
      "terms found cum\n",
      "terms found cums\n",
      "terms found cunt\n",
      "terms found cunts\n",
      "terms found aps\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fucked\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found hoe\n",
      "terms found hoes\n",
      "terms found homo\n",
      "terms found jerk\n",
      "terms found kill\n",
      "terms found masturbate\n",
      "terms found mean\n",
      "terms found mf\n",
      "terms found mfo\n",
      "terms found orgasm\n",
      "terms found orgasms\n",
      "terms found piss\n",
      "terms found piss\n",
      "terms found aps\n",
      "terms found pissin\n",
      "terms found pissing\n",
      "terms found poop\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitting\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_girl_collocation = pd.read_csv(collocation_folder+\"/reddit_girl_collocation.csv\")\n",
    "reddit_girl_collocation_insults1 = find_list_of_words_in_df(reddit_girl_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_girl_collocation_insults2 = find_list_of_words_in_df(reddit_girl_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_girl_collocation_insults = pd.concat([reddit_girl_collocation_insults1,reddit_girl_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d88dd5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl insultive collocation average PMI: 3.447308658379964\n"
     ]
    }
   ],
   "source": [
    "print(\"girl insultive collocation average PMI:\",np.mean(reddit_girl_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a760556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found anal\n",
      "terms found ass\n",
      "terms found bad\n",
      "terms found boob\n",
      "terms found boobs\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found jap\n",
      "terms found retard\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n",
      "terms found tits\n",
      "terms found arse\n",
      "terms found ass\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found jap\n",
      "terms found kick\n",
      "terms found penis\n",
      "terms found pron\n",
      "terms found vagina\n"
     ]
    }
   ],
   "source": [
    "reddit_asian_collocation = pd.read_csv(collocation_folder+\"/reddit_asian_collocation.csv\")\n",
    "reddit_asian_collocation = reddit_asian_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_asian_collocation_insults1 = find_list_of_words_in_df(reddit_asian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_asian_collocation_insults2 = find_list_of_words_in_df(reddit_asian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_asian_collocation_insults = pd.concat([reddit_asian_collocation_insults1,reddit_asian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1162b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asian insultive collocation average PMI: 5.948219582639393\n"
     ]
    }
   ],
   "source": [
    "print(\"asian insultive collocation average PMI:\",np.mean(reddit_asian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "320544c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_hispanic_collocation = pd.read_csv(collocation_folder+\"/reddit_hispanic_collocation.csv\")\n",
    "reddit_hispanic_collocation = reddit_hispanic_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_hispanic_collocation_insults1 = find_list_of_words_in_df(reddit_hispanic_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_hispanic_collocation_insults2 = find_list_of_words_in_df(reddit_hispanic_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_hispanic_collocation_insults = pd.concat([reddit_hispanic_collocation_insults1,reddit_hispanic_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "074796a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found cum\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found anal\n",
      "terms found cum\n",
      "terms found fuck\n",
      "terms found homo\n",
      "terms found hore\n",
      "terms found kill\n",
      "terms found lust\n",
      "terms found lusting\n",
      "terms found nazi\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n",
      "terms found whore\n"
     ]
    }
   ],
   "source": [
    "reddit_homosexual_collocation = pd.read_csv(collocation_folder+\"/reddit_homosexual_collocation.csv\")\n",
    "reddit_homosexual_collocation = reddit_homosexual_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_homosexual_collocation_insults1 = find_list_of_words_in_df(reddit_homosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_homosexual_collocation_insults2 = find_list_of_words_in_df(reddit_homosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_homosexual_collocation_insults = pd.concat([reddit_homosexual_collocation_insults1,reddit_homosexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec011e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homosexual insultive collocation average PMI: 6.666081049457262\n"
     ]
    }
   ],
   "source": [
    "print(\"homosexual insultive collocation average PMI:\",np.mean(reddit_homosexual_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76d1540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found fag\n",
      "terms found faggot\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found queer\n",
      "terms found tit\n",
      "terms found bad\n",
      "terms found dick\n",
      "terms found fuck\n",
      "terms found mean\n",
      "terms found queer\n",
      "terms found sex\n"
     ]
    }
   ],
   "source": [
    "reddit_queer_collocation = pd.read_csv(collocation_folder+\"/reddit_queer_collocation.csv\")\n",
    "reddit_queer_collocation = reddit_queer_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_queer_collocation_insults1 = find_list_of_words_in_df(reddit_queer_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_queer_collocation_insults2 = find_list_of_words_in_df(reddit_queer_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_queer_collocation_insults = pd.concat([reddit_queer_collocation_insults1,reddit_queer_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "225fdbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queer insultive collocation average PMI: 7.5175378336924705\n"
     ]
    }
   ],
   "source": [
    "print(\"queer insultive collocation average PMI:\",np.mean(reddit_queer_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "974021f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found cunt\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hore\n",
      "terms found jap\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found slut\n",
      "terms found spunk\n",
      "terms found stupid\n",
      "terms found ugly\n",
      "terms found whore\n",
      "terms found anus\n",
      "terms found ass\n",
      "terms found asses\n",
      "terms found asshole\n",
      "terms found bad\n",
      "terms found bich\n",
      "terms found blowjob\n",
      "terms found blowjobs\n",
      "terms found breasts\n",
      "terms found butt\n",
      "terms found coon\n",
      "terms found cum\n",
      "terms found cums\n",
      "terms found ejaculate\n",
      "terms found fag\n",
      "terms found faggot\n",
      "terms found aps\n",
      "terms found hell\n",
      "terms found homo\n",
      "terms found kick\n",
      "terms found orgasm\n",
      "terms found orgasms\n",
      "terms found penis\n",
      "terms found aps\n",
      "terms found pron\n",
      "terms found queer\n",
      "terms found retard\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found sob\n",
      "terms found spac\n",
      "terms found stfu\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_female_collocation = pd.read_csv(collocation_folder+\"/reddit_female_collocation.csv\")\n",
    "reddit_female_collocation = reddit_female_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_female_collocation_insults1 = find_list_of_words_in_df(reddit_female_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_female_collocation_insults2 = find_list_of_words_in_df(reddit_female_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_female_collocation_insults = pd.concat([reddit_female_collocation_insults1,reddit_female_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77681094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female insultive collocation average PMI: 6.245545721308111\n"
     ]
    }
   ],
   "source": [
    "print(\"female insultive collocation average PMI:\",np.mean(reddit_female_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0145e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found bastard\n",
      "terms found butt\n",
      "terms found cum\n",
      "terms found aps\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found fucks\n",
      "terms found hate\n",
      "terms found idiot\n",
      "terms found kick\n",
      "terms found kill\n",
      "terms found lick\n",
      "terms found mean\n",
      "terms found nazi\n",
      "terms found aps\n",
      "terms found retard\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shithead\n",
      "terms found shitty\n",
      "terms found stupid\n",
      "terms found tit\n",
      "terms found ugly\n",
      "terms found anal\n",
      "terms found anus\n",
      "terms found arse\n",
      "terms found ass\n",
      "terms found asses\n",
      "terms found bad\n",
      "terms found balls\n",
      "terms found bastard\n",
      "terms found bitch\n",
      "terms found bitches\n",
      "terms found butt\n",
      "terms found cock\n",
      "terms found cum\n",
      "terms found cunt\n",
      "terms found dick\n",
      "terms found dildo\n",
      "terms found dildos\n",
      "terms found disgusting\n",
      "terms found fag\n",
      "terms found faggot\n",
      "terms found aps\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found gangbang\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found hoe\n",
      "terms found hoes\n",
      "terms found hore\n",
      "terms found jap\n",
      "terms found kill\n",
      "terms found knob\n",
      "terms found lust\n",
      "terms found mean\n",
      "terms found penis\n",
      "terms found aps\n",
      "terms found poop\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found spac\n",
      "terms found suck\n",
      "terms found tit\n",
      "terms found titt\n",
      "terms found tittie\n",
      "terms found titties\n",
      "terms found whore\n",
      "terms found wse\n"
     ]
    }
   ],
   "source": [
    "reddit_black_collocation = pd.read_csv(collocation_folder+\"/reddit_black_collocation.csv\")\n",
    "reddit_black_collocation = reddit_black_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_black_collocation_insults1 = find_list_of_words_in_df(reddit_black_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_black_collocation_insults2 = find_list_of_words_in_df(reddit_black_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_black_collocation_insults = pd.concat([reddit_black_collocation_insults1,reddit_black_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82d95440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black insultive collocation average PMI: 3.779829932911182\n"
     ]
    }
   ],
   "source": [
    "print(\"black insultive collocation average PMI:\",np.mean(reddit_black_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc59a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found hate\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found ass\n",
      "terms found penis\n",
      "terms found sex\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_indian_collocation = pd.read_csv(collocation_folder+\"/reddit_indian_collocation.csv\")\n",
    "reddit_indian_collocation = reddit_indian_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_indian_collocation_insults1 = find_list_of_words_in_df(reddit_indian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_indian_collocation_insults2 = find_list_of_words_in_df(reddit_indian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_indian_collocation_insults = pd.concat([reddit_indian_collocation_insults1,reddit_indian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a0d15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian insultive collocation average PMI: 6.669130030472756\n"
     ]
    }
   ],
   "source": [
    "print(\"indian insultive collocation average PMI:\",np.mean(reddit_indian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5fbe99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_non_binary_collocation = pd.read_csv(collocation_folder+\"/reddit_non-binary_collocation.csv\")\n",
    "reddit_non_binary_collocation = reddit_non_binary_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_non_binary_collocation_insults1 = find_list_of_words_in_df(reddit_non_binary_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_non_binary_collocation_insults2 = find_list_of_words_in_df(reddit_non_binary_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_non_binary_collocation_insults = pd.concat([reddit_non_binary_collocation_insults1,reddit_non_binary_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86fa11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
