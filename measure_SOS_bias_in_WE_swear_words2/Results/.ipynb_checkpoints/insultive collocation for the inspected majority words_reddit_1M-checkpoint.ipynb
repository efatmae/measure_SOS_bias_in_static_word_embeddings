{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb09c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661846fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_of_words_in_df(df, slur_list, text_col):\n",
    "  ps_in_hateEval = []\n",
    "  for i in slur_list: \n",
    "    if  df[text_col].str.contains(i).any() == True:\n",
    "      print(\"terms found \"+ i)  \n",
    "      ps_mid = df[df[text_col].str.contains(i)]\n",
    "      ps_in_hateEval.append(ps_mid)\n",
    "      \n",
    "  if len(ps_in_hateEval)>0:\n",
    "      ps_in_hateEval_df = pd.concat(ps_in_hateEval)\n",
    "      return ps_in_hateEval_df\n",
    "  else:\n",
    "        print (\"Nothing found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d262f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e1978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_words = open(data_folder+\"swear_words.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd07dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_folder = \"./collocation_results_1M_reddit/majority/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e78617dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reddit_father_collocation.csv',\n",
       " 'reddit_caucasian_collocation.csv',\n",
       " 'reddit_canadian_collocation.csv',\n",
       " 'reddit_australian_collocation.csv',\n",
       " 'reddit_english_collocation.csv',\n",
       " 'reddit_cisgender_collocation.csv',\n",
       " 'reddit_german_collocation.csv',\n",
       " 'reddit_boy_collocation.csv',\n",
       " 'reddit_son_collocation.csv',\n",
       " 'reddit_hetrosexual_collocation.csv',\n",
       " 'reddit_man_collocation.csv',\n",
       " 'reddit_dutch_collocation.csv',\n",
       " 'reddit_european_collocation.csv',\n",
       " 'reddit_norwegian_collocation.csv',\n",
       " 'reddit_american_collocation.csv',\n",
       " 'reddit_french_collocation.csv',\n",
       " 'reddit_brother_collocation.csv',\n",
       " 'reddit_swedish_collocation.csv',\n",
       " 'reddit_male_collocation.csv',\n",
       " 'reddit_husband_collocation.csv',\n",
       " 'reddit_white_collocation.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(collocation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8005585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found jap\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found fat\n",
      "terms found hate\n"
     ]
    }
   ],
   "source": [
    "reddit_father_collocation = pd.read_csv(collocation_folder+\"/reddit_father_collocation.csv\")\n",
    "reddit_father_collocation_insults1 = find_list_of_words_in_df(reddit_father_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_father_collocation_insults2 = find_list_of_words_in_df(reddit_father_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_father_collocation_insults = pd.concat([reddit_father_collocation_insults1,reddit_father_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfd486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father insultive collocation average PMI: 5.8706219006586275\n"
     ]
    }
   ],
   "source": [
    "print(\"father insultive collocation average PMI:\",np.mean(reddit_father_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72215a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found mean\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_caucasian_collocation = pd.read_csv(collocation_folder+\"/reddit_caucasian_collocation.csv\")\n",
    "reddit_caucasian_collocation_insults1 = find_list_of_words_in_df(reddit_caucasian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_caucasian_collocation_insults2 = find_list_of_words_in_df(reddit_caucasian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_caucasian_collocation_insults = pd.concat([reddit_caucasian_collocation_insults1,reddit_caucasian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57aa36e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caucasian insultive collocation average PMI: 9.070779234681591\n"
     ]
    }
   ],
   "source": [
    "print(\"caucasian insultive collocation average PMI:\",np.mean(reddit_caucasian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57aad828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found kill\n",
      "terms found sex\n",
      "terms found ass\n"
     ]
    }
   ],
   "source": [
    "reddit_canadian_collocation = pd.read_csv(collocation_folder+\"/reddit_canadian_collocation.csv\")\n",
    "reddit_canadian_collocation_insults1 = find_list_of_words_in_df(reddit_canadian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_canadian_collocation_insults2 = find_list_of_words_in_df(reddit_canadian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_canadian_collocation_insults = pd.concat([reddit_canadian_collocation_insults1,reddit_canadian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca9ae1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canadian insultive collocation average PMI: 11.672928636485096\n"
     ]
    }
   ],
   "source": [
    "print(\"canadian insultive collocation average PMI:\",np.mean(reddit_canadian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf642de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found ass\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_australian_collocation = pd.read_csv(collocation_folder+\"/reddit_australian_collocation.csv\")\n",
    "reddit_australian_collocation_insults1 = find_list_of_words_in_df(reddit_australian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_australian_collocation_insults2 = find_list_of_words_in_df(reddit_australian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_australian_collocation_insults = pd.concat([reddit_australian_collocation_insults1,reddit_australian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a2f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "australian insultive collocation average PMI: 8.909826660387925\n"
     ]
    }
   ],
   "source": [
    "print(\"australian insultive collocation average PMI:\",np.mean(reddit_australian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c0f092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found ass\n",
      "terms found asses\n",
      "terms found aps\n",
      "terms found fuck\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found muff\n",
      "terms found nazi\n",
      "terms found aps\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_english_collocation = pd.read_csv(collocation_folder+\"/reddit_english_collocation.csv\")\n",
    "reddit_english_collocation_insults1 = find_list_of_words_in_df(reddit_english_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_english_collocation_insults2 = find_list_of_words_in_df(reddit_english_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_english_collocation_insults = pd.concat([reddit_english_collocation_insults1,reddit_english_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809fcbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english insultive collocation average PMI: 5.817349614223487\n"
     ]
    }
   ],
   "source": [
    "print(\"english insultive collocation average PMI:\",np.mean(reddit_english_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b062718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_cisgender_collocation = pd.read_csv(collocation_folder+\"/reddit_cisgender_collocation.csv\")\n",
    "reddit_cisgender_collocation_insults1 = find_list_of_words_in_df(reddit_cisgender_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_cisgender_collocation_insults2 = find_list_of_words_in_df(reddit_cisgender_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_cisgender_collocation_insults = pd.concat([reddit_cisgender_collocation_insults1,reddit_cisgender_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c6ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_german_collocation = pd.read_csv(collocation_folder+\"/reddit_german_collocation.csv\")\n",
    "reddit_german_collocation_insults1 = find_list_of_words_in_df(reddit_german_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_german_collocation_insults2 = find_list_of_words_in_df(reddit_german_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_german_collocation_insults = pd.concat([reddit_german_collocation_insults1,reddit_german_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d63ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found bitch\n",
      "terms found butt\n",
      "terms found dirty\n",
      "terms found fat\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found kill\n"
     ]
    }
   ],
   "source": [
    "reddit_boy_collocation = pd.read_csv(collocation_folder+\"/reddit_boy_collocation.csv\")\n",
    "reddit_boy_collocation_insults1 = find_list_of_words_in_df(reddit_boy_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_boy_collocation_insults2 = find_list_of_words_in_df(reddit_boy_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_boy_collocation_insults = pd.concat([reddit_boy_collocation_insults1,reddit_boy_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d32e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy insultive collocation average PMI: 6.908504689235548\n"
     ]
    }
   ],
   "source": [
    "print(\"boy insultive collocation average PMI:\",np.mean(reddit_boy_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d3b4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found balls\n",
      "terms found dumb\n",
      "terms found dumbass\n",
      "terms found fat\n",
      "terms found lick\n",
      "terms found sex\n"
     ]
    }
   ],
   "source": [
    "reddit_son_collocation = pd.read_csv(collocation_folder+\"/reddit_son_collocation.csv\")\n",
    "reddit_son_collocation_insults1 = find_list_of_words_in_df(reddit_son_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_son_collocation_insults2 = find_list_of_words_in_df(reddit_son_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_son_collocation_insults = pd.concat([reddit_son_collocation_insults1,reddit_son_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74bf75b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son insultive collocation average PMI: 7.614426630506494\n"
     ]
    }
   ],
   "source": [
    "print(\"son insultive collocation average PMI:\",np.mean(reddit_son_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a56fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_hetrosexual_collocation = pd.read_csv(collocation_folder+\"/reddit_hetrosexual_collocation.csv\")\n",
    "reddit_hetrosexual_collocation_insults1 = find_list_of_words_in_df(reddit_hetrosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_hetrosexual_collocation_insults2 = find_list_of_words_in_df(reddit_hetrosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_hetrosexual_collocation_insults = pd.concat([reddit_hetrosexual_collocation_insults1,reddit_hetrosexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3c6ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found dick\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found lust\n",
      "terms found mean\n",
      "terms found nigga\n",
      "terms found retard\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found stupid\n",
      "terms found suck\n",
      "terms found wse\n",
      "terms found ass\n",
      "terms found asshole\n",
      "terms found assholes\n",
      "terms found boob\n",
      "terms found boobs\n",
      "terms found disgusting\n",
      "terms found fat\n",
      "terms found hore\n",
      "terms found mean\n",
      "terms found nigga\n",
      "terms found smell\n",
      "terms found tit\n",
      "terms found tits\n",
      "terms found titt\n",
      "terms found tittie\n",
      "terms found titties\n",
      "terms found whore\n"
     ]
    }
   ],
   "source": [
    "reddit_man_collocation = pd.read_csv(collocation_folder+\"/reddit_man_collocation.csv\")\n",
    "reddit_man_collocation_insults1 = find_list_of_words_in_df(reddit_man_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_man_collocation_insults2 = find_list_of_words_in_df(reddit_man_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_man_collocation_insults = pd.concat([reddit_man_collocation_insults1,reddit_man_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cf7733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man insultive collocation average PMI: 4.837211981092521\n"
     ]
    }
   ],
   "source": [
    "print(\"man insultive collocation average PMI:\",np.mean(reddit_man_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f30802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found dirty\n",
      "terms found kill\n",
      "terms found hell\n",
      "terms found kick\n"
     ]
    }
   ],
   "source": [
    "reddit_dutch_collocation = pd.read_csv(collocation_folder+\"/reddit_dutch_collocation.csv\")\n",
    "reddit_dutch_collocation_insults1 = find_list_of_words_in_df(reddit_dutch_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_dutch_collocation_insults2 = find_list_of_words_in_df(reddit_dutch_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_dutch_collocation_insults = pd.concat([reddit_dutch_collocation_insults1,reddit_dutch_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3bd2704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dutch insultive collocation average PMI: 10.174098859844849\n"
     ]
    }
   ],
   "source": [
    "print(\"dutch insultive collocation average PMI:\",np.mean(reddit_dutch_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de80e401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found dirty\n",
      "terms found kill\n",
      "terms found ass\n",
      "terms found aps\n",
      "terms found aps\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_european_collocation = pd.read_csv(collocation_folder+\"/reddit_european_collocation.csv\")\n",
    "reddit_european_collocation_insults1 = find_list_of_words_in_df(reddit_european_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_european_collocation_insults2 = find_list_of_words_in_df(reddit_european_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_european_collocation_insults = pd.concat([reddit_european_collocation_insults1,reddit_european_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "630d54c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "european insultive collocation average PMI: 8.21267670571344\n"
     ]
    }
   ],
   "source": [
    "print(\"european insultive collocation average PMI:\",np.mean(reddit_european_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917d873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_norwegian_collocation = pd.read_csv(collocation_folder+\"/reddit_norwegian_collocation.csv\")\n",
    "reddit_norwegian_collocation_insults1 = find_list_of_words_in_df(reddit_norwegian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_norwegian_collocation_insults2 = find_list_of_words_in_df(reddit_norwegian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_norwegian_collocation_insults = pd.concat([reddit_norwegian_collocation_insults1,reddit_norwegian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07b61c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found dumb\n",
      "terms found kill\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found ass\n",
      "terms found fuck\n",
      "terms found hore\n",
      "terms found mean\n",
      "terms found shi\n",
      "terms found spac\n",
      "terms found tit\n",
      "terms found whore\n"
     ]
    }
   ],
   "source": [
    "reddit_american_collocation = pd.read_csv(collocation_folder+\"/reddit_american_collocation.csv\")\n",
    "reddit_american_collocation_insults1 = find_list_of_words_in_df(reddit_american_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_american_collocation_insults2 = find_list_of_words_in_df(reddit_american_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_american_collocation_insults = pd.concat([reddit_american_collocation_insults1,reddit_american_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20a7b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american insultive collocation average PMI: 5.073694771803882\n"
     ]
    }
   ],
   "source": [
    "print(\"american insultive collocation average PMI:\",np.mean(reddit_american_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5190b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found ass\n",
      "terms found bastard\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_french_collocation = pd.read_csv(collocation_folder+\"/reddit_french_collocation.csv\")\n",
    "reddit_french_collocation_insults1 = find_list_of_words_in_df(reddit_french_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_french_collocation_insults2 = find_list_of_words_in_df(reddit_french_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_french_collocation_insults = pd.concat([reddit_french_collocation_insults1,reddit_french_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2689f6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french insultive collocation average PMI: 9.307130602761697\n"
     ]
    }
   ],
   "source": [
    "print(\"french insultive collocation average PMI:\",np.mean(reddit_french_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f06e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bastard\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found ass\n",
      "terms found kill\n",
      "terms found piss\n",
      "terms found pissed\n",
      "terms found piss\n"
     ]
    }
   ],
   "source": [
    "reddit_brother_collocation = pd.read_csv(collocation_folder+\"/reddit_brother_collocation.csv\")\n",
    "\n",
    "reddit_brother_collocation_insults1 = find_list_of_words_in_df(reddit_brother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_brother_collocation_insults2 = find_list_of_words_in_df(reddit_brother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_brother_collocation_insults = pd.concat([reddit_brother_collocation_insults1,reddit_brother_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2d1107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brother insultive collocation average PMI: 4.926409844530102\n"
     ]
    }
   ],
   "source": [
    "print(\"brother insultive collocation average PMI:\",np.mean(reddit_brother_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e99b8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found shi\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_swedish_collocation = pd.read_csv(collocation_folder+\"/reddit_swedish_collocation.csv\")\n",
    "\n",
    "reddit_swedish_collocation_insults1 = find_list_of_words_in_df(reddit_swedish_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_swedish_collocation_insults2 = find_list_of_words_in_df(reddit_swedish_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_swedish_collocation_insults = pd.concat([reddit_swedish_collocation_insults1,reddit_swedish_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "455305b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swedish insultive collocation average PMI: 10.787693939123699\n"
     ]
    }
   ],
   "source": [
    "print(\"swedish insultive collocation average PMI:\",np.mean(reddit_swedish_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abf8241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found cum\n",
      "terms found homo\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found ass\n",
      "terms found cum\n",
      "terms found kill\n",
      "terms found pron\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_male_collocation = pd.read_csv(collocation_folder+\"/reddit_male_collocation.csv\")\n",
    "\n",
    "reddit_male_collocation_insults1 = find_list_of_words_in_df(reddit_male_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_male_collocation_insults2 = find_list_of_words_in_df(reddit_male_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_male_collocation_insults = pd.concat([reddit_male_collocation_insults1,reddit_male_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21aef886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male insultive collocation average PMI: 7.695963643314757\n"
     ]
    }
   ],
   "source": [
    "print(\"male insultive collocation average PMI:\",np.mean(reddit_male_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f9e535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found jerk\n",
      "terms found sex\n"
     ]
    }
   ],
   "source": [
    "reddit_husband_collocation = pd.read_csv(collocation_folder+\"/reddit_husband_collocation.csv\")\n",
    "\n",
    "reddit_husband_collocation_insults1 = find_list_of_words_in_df(reddit_husband_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_husband_collocation_insults2 = find_list_of_words_in_df(reddit_husband_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_husband_collocation_insults = pd.concat([reddit_husband_collocation_insults1,reddit_husband_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e91d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "husband insultive collocation average PMI: 9.097747775620423\n"
     ]
    }
   ],
   "source": [
    "print(\"husband insultive collocation average PMI:\",np.mean(reddit_husband_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1585fb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found idiot\n",
      "terms found mean\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found ass\n",
      "terms found asses\n",
      "terms found balls\n",
      "terms found aps\n",
      "terms found fuck\n",
      "terms found fucks\n",
      "terms found jiz\n",
      "terms found jizz\n",
      "terms found aps\n",
      "terms found shi\n",
      "terms found spac\n"
     ]
    }
   ],
   "source": [
    "reddit_white_collocation = pd.read_csv(collocation_folder+\"/reddit_white_collocation.csv\")\n",
    "\n",
    "reddit_white_collocation_insults1 = find_list_of_words_in_df(reddit_white_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_white_collocation_insults2 = find_list_of_words_in_df(reddit_white_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_white_collocation_insults = pd.concat([reddit_white_collocation_insults1,reddit_white_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "947827ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white insultive collocation average PMI: 5.72370364722497\n"
     ]
    }
   ],
   "source": [
    "print(\"white insultive collocation average PMI:\",np.mean(reddit_white_collocation_insults.PMI))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
