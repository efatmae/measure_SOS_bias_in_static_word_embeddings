{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d507adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f65d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_of_words_in_df(df, slur_list, text_col):\n",
    "  ps_in_hateEval = []\n",
    "  for i in slur_list: \n",
    "    if  df[text_col].str.contains(i).any() == True:\n",
    "      print(\"terms found \"+ i)  \n",
    "      ps_mid = df[df[text_col].str.contains(i)]\n",
    "      ps_in_hateEval.append(ps_mid)\n",
    "      \n",
    "  if len(ps_in_hateEval)>0:\n",
    "      ps_in_hateEval_df = pd.concat(ps_in_hateEval)\n",
    "      return ps_in_hateEval_df\n",
    "  else:\n",
    "        print (\"Nothing found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ddcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15d61ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_words = open(data_folder+\"swear_words.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a2bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_folder = \"./collocation_results_100K_reddict/minority/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d11d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './collocation_results/minority/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b050b7820b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollocation_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './collocation_results/minority/'"
     ]
    }
   ],
   "source": [
    "os.listdir(collocation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dfc9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_transgender_collocation = pd.read_csv(collocation_folder+\"/reddit_transgender_collocation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac1cf5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_transgender_collocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a4da64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'word1', 'word2', 'PMI'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_transgender_collocation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b69d0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_transgender_collocation_insults = find_list_of_words_in_df(reddit_transgender_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80ada15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_lgtbq_collocation = pd.read_csv(collocation_folder+\"/reddit_lgtbq_collocation.csv\")\n",
    "reddit_lgtbq_collocation_insults1 = find_list_of_words_in_df(reddit_lgtbq_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lgtbq_collocation_insults2 = find_list_of_words_in_df(reddit_lgtbq_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "711cf311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bitch\n",
      "terms found sex\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_lesbian_collocation = pd.read_csv(collocation_folder+\"/reddit_lesbian_collocation.csv\")\n",
    "reddit_lesbian_collocation_insults1 = find_list_of_words_in_df(reddit_lesbian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lesbian_collocation_insults2 = find_list_of_words_in_df(reddit_lesbian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_lesbian_collocation_insults = pd.concat([reddit_lesbian_collocation_insults1,reddit_lesbian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "686d2f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesbian insultive collocation average PMI: 9.446476248839735\n"
     ]
    }
   ],
   "source": [
    "print(\"lesbian insultive collocation average PMI:\",np.mean(reddit_lesbian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1af0263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found retard\n",
      "terms found fuck\n",
      "terms found fucker\n",
      "terms found fuckers\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found kill\n",
      "terms found shi\n"
     ]
    }
   ],
   "source": [
    "reddit_mother_collocation = pd.read_csv(collocation_folder+\"/reddit_mother_collocation.csv\")\n",
    "reddit_mother_collocation_insults1 = find_list_of_words_in_df(reddit_mother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_mother_collocation_insults2 = find_list_of_words_in_df(reddit_mother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_mother_collocation_insults = pd.concat([reddit_mother_collocation_insults1,reddit_mother_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c89a262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother insultive collocation average PMI: 6.154385904068221\n"
     ]
    }
   ],
   "source": [
    "print(\"mother insultive collocation average PMI:\",np.mean(reddit_mother_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93395db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found dyke\n",
      "terms found aps\n",
      "terms found horny\n",
      "terms found aps\n",
      "terms found ass\n",
      "terms found bad\n",
      "terms found hate\n"
     ]
    }
   ],
   "source": [
    "reddit_wife_collocation = pd.read_csv(collocation_folder+\"/reddit_wife_collocation.csv\")\n",
    "reddit_wife_collocation_insults1 = find_list_of_words_in_df(reddit_wife_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_wife_collocation_insults2 = find_list_of_words_in_df(reddit_wife_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_wife_collocation_insults = pd.concat([reddit_wife_collocation_insults1,reddit_wife_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a75f0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wife insultive collocation average PMI: 7.46867475604032\n"
     ]
    }
   ],
   "source": [
    "print(\"wife insultive collocation average PMI:\",np.mean(reddit_wife_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faee20cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found sex\n",
      "terms found fat\n"
     ]
    }
   ],
   "source": [
    "reddit_trans_collocation = pd.read_csv(collocation_folder+\"/reddit_trans_collocation.csv\")\n",
    "reddit_trans_collocation_insults1 = find_list_of_words_in_df(reddit_trans_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_trans_collocation_insults2 = find_list_of_words_in_df(reddit_trans_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_trans_collocation_insults = pd.concat([reddit_trans_collocation_insults1,reddit_trans_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82c3e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans insultive collocation average PMI: 12.25952561318715\n"
     ]
    }
   ],
   "source": [
    "print(\"trans insultive collocation average PMI:\",np.mean(reddit_trans_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "147547b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_latino_collocation = pd.read_csv(collocation_folder+\"/reddit_latino_collocation.csv\")\n",
    "reddit_latino_collocation_insults1 = find_list_of_words_in_df(reddit_latino_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_latino_collocation_insults2 = find_list_of_words_in_df(reddit_latino_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_latino_collocation_insults = pd.concat([reddit_latino_collocation_insults1,reddit_latino_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6254940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found fat\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_daughter_collocation = pd.read_csv(collocation_folder+\"/reddit_daughter_collocation.csv\")\n",
    "reddit_daughter_collocation_insults1 = find_list_of_words_in_df(reddit_daughter_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_daughter_collocation_insults2 = find_list_of_words_in_df(reddit_daughter_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_latino_collocation_insults = pd.concat([reddit_latino_collocation_insults1,reddit_latino_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "710bea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daughter insultive collocation average PMI: 5.8679615710266395\n"
     ]
    }
   ],
   "source": [
    "print(\"daughter insultive collocation average PMI:\",np.mean(reddit_daughter_collocation_insults1.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e87ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found sex\n",
      "terms found sex\n"
     ]
    }
   ],
   "source": [
    "reddit_bisexual_collocation = pd.read_csv(collocation_folder+\"/reddit_bisexual_collocation.csv\")\n",
    "reddit_bisexual_collocation_insults1 = find_list_of_words_in_df(reddit_bisexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_bisexual_collocation_insults2 = find_list_of_words_in_df(reddit_bisexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_bisexual_collocation_insults = pd.concat([reddit_bisexual_collocation_insults1,reddit_bisexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f88ed2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bisexual insultive collocation average PMI: 9.756275755080061\n"
     ]
    }
   ],
   "source": [
    "print(\"bisexual insultive collocation average PMI:\",np.mean(reddit_bisexual_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae1b5768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found kill\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_negro_collocation = pd.read_csv(collocation_folder+\"/reddit_negro_collocation.csv\")\n",
    "reddit_negro_collocation_insults1 = find_list_of_words_in_df(reddit_negro_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_negro_collocation_insults2 = find_list_of_words_in_df(reddit_negro_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_negro_collocation_insults = pd.concat([reddit_negro_collocation_insults1,reddit_negro_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddde7b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negro insultive collocation average PMI: 10.363294336641166\n"
     ]
    }
   ],
   "source": [
    "print(\"negro insultive collocation average PMI:\",np.mean(reddit_negro_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fce511ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_arab_collocation = pd.read_csv(collocation_folder+\"/reddit_arab_collocation.csv\")\n",
    "reddit_arab_collocation_insults1 = find_list_of_words_in_df(reddit_arab_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_arab_collocation_insults2 = find_list_of_words_in_df(reddit_arab_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_arab_collocation_insults = pd.concat([reddit_arab_collocation_insults1,reddit_arab_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1598a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arab insultive collocation average PMI: 11.1632030742159\n"
     ]
    }
   ],
   "source": [
    "print(\"arab insultive collocation average PMI:\",np.mean(reddit_arab_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa6df97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found aps\n",
      "terms found aps\n"
     ]
    }
   ],
   "source": [
    "reddit_sister_collocation = pd.read_csv(collocation_folder+\"/reddit_sister_collocation.csv\")\n",
    "reddit_sister_collocation_insults1 = find_list_of_words_in_df(reddit_sister_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_sister_collocation_insults2 = find_list_of_words_in_df(reddit_sister_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_sister_collocation_insults = pd.concat([reddit_sister_collocation_insults1,reddit_sister_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3407f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister insultive collocation average PMI: 14.087254220982608\n"
     ]
    }
   ],
   "source": [
    "print(\"sister insultive collocation average PMI:\",np.mean(reddit_sister_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe2ee33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bitch\n",
      "terms found boob\n",
      "terms found butt\n",
      "terms found jap\n",
      "terms found sex\n",
      "terms found ugly\n",
      "terms found cum\n",
      "terms found hate\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_woman_collocation = pd.read_csv(collocation_folder+\"/reddit_woman_collocation.csv\")\n",
    "reddit_woman_collocation_insults1 = find_list_of_words_in_df(reddit_woman_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_woman_collocation_insults2 = find_list_of_words_in_df(reddit_woman_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_woman_collocation_insults = pd.concat([reddit_woman_collocation_insults1,reddit_woman_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92d5781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman insultive collocation average PMI: 6.121113306028144\n"
     ]
    }
   ],
   "source": [
    "print(\"woman insultive collocation average PMI:\",np.mean(reddit_woman_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37a17eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bitch\n",
      "terms found dumb\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found idiot\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found tit\n",
      "terms found butt\n",
      "terms found fag\n",
      "terms found fags\n",
      "terms found jerk\n",
      "terms found mean\n",
      "terms found penis\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_gay_collocation = pd.read_csv(collocation_folder+\"/reddit_gay_collocation.csv\")\n",
    "reddit_gay_collocation_insults1 = find_list_of_words_in_df(reddit_gay_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_gay_collocation_insults2 = find_list_of_words_in_df(reddit_gay_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_gay_collocation_insults = pd.concat([reddit_gay_collocation_insults1,reddit_gay_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "202b6d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gay insultive collocation average PMI: 6.322586868064068\n"
     ]
    }
   ],
   "source": [
    "print(\"gay insultive collocation average PMI:\",np.mean(reddit_gay_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94683b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_african_collocation = pd.read_csv(collocation_folder+\"/reddit_african_collocation.csv\")\n",
    "reddit_african_collocation_insults1 = find_list_of_words_in_df(reddit_african_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_african_collocation_insults2 = find_list_of_words_in_df(reddit_african_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_african_collocation_insults = pd.concat([reddit_african_collocation_insults1,reddit_african_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f332edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "african insultive collocation average PMI: 11.8257619799572\n"
     ]
    }
   ],
   "source": [
    "print(\"african insultive collocation average PMI:\",np.mean(reddit_african_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f5ac92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found cum\n",
      "terms found fat\n",
      "terms found shi\n",
      "terms found ass\n",
      "terms found cok\n"
     ]
    }
   ],
   "source": [
    "reddit_mexican_collocation = pd.read_csv(collocation_folder+\"/reddit_mexican_collocation.csv\")\n",
    "reddit_mexican_collocation_insults1 = find_list_of_words_in_df(reddit_mexican_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_mexican_collocation_insults2 = find_list_of_words_in_df(reddit_mexican_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_mexican_collocation_insults = pd.concat([reddit_mexican_collocation_insults1,reddit_mexican_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51fae0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mexican insultive collocation average PMI: 8.903277108008933\n"
     ]
    }
   ],
   "source": [
    "print(\"mexican insultive collocation average PMI:\",np.mean(reddit_mexican_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e727852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_lgtb_collocation = pd.read_csv(collocation_folder+\"/reddit_lgtb_collocation.csv\")\n",
    "reddit_lgtb_collocation_insults1 = find_list_of_words_in_df(reddit_lgtb_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lgtb_collocation_insults2 = find_list_of_words_in_df(reddit_lgtb_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_lgtb_collocation_insults = pd.concat([reddit_lgtb_collocation_insults1,reddit_lgtb_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f07722d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found dumb\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found jap\n",
      "terms found sex\n",
      "terms found stupid\n",
      "terms found ugly\n",
      "terms found boob\n",
      "terms found boobs\n",
      "terms found hate\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitting\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_girl_collocation = pd.read_csv(collocation_folder+\"/reddit_girl_collocation.csv\")\n",
    "reddit_girl_collocation_insults1 = find_list_of_words_in_df(reddit_girl_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_girl_collocation_insults2 = find_list_of_words_in_df(reddit_girl_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_girl_collocation_insults = pd.concat([reddit_girl_collocation_insults1,reddit_girl_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38b8b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl insultive collocation average PMI: 3.7360721742242604\n"
     ]
    }
   ],
   "source": [
    "print(\"girl insultive collocation average PMI:\",np.mean(reddit_girl_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2fec8805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found homo\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found bitch\n"
     ]
    }
   ],
   "source": [
    "reddit_asian_collocation = pd.read_csv(collocation_folder+\"/reddit_asian_collocation.csv\")\n",
    "reddit_asian_collocation = reddit_asian_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_asian_collocation_insults1 = find_list_of_words_in_df(reddit_asian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_asian_collocation_insults2 = find_list_of_words_in_df(reddit_asian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_asian_collocation_insults = pd.concat([reddit_asian_collocation_insults1,reddit_asian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1fadadae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asian insultive collocation average PMI: 7.053557133484275\n"
     ]
    }
   ],
   "source": [
    "print(\"asian insultive collocation average PMI:\",np.mean(reddit_asian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af42c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_hispanic_collocation = pd.read_csv(collocation_folder+\"/reddit_hispanic_collocation.csv\")\n",
    "reddit_hispanic_collocation = reddit_hispanic_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_hispanic_collocation_insults1 = find_list_of_words_in_df(reddit_hispanic_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_hispanic_collocation_insults2 = find_list_of_words_in_df(reddit_hispanic_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_hispanic_collocation_insults = pd.concat([reddit_hispanic_collocation_insults1,reddit_hispanic_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "104af3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found homo\n",
      "terms found sex\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found shi\n"
     ]
    }
   ],
   "source": [
    "reddit_homosexual_collocation = pd.read_csv(collocation_folder+\"/reddit_homosexual_collocation.csv\")\n",
    "reddit_homosexual_collocation = reddit_homosexual_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_homosexual_collocation_insults1 = find_list_of_words_in_df(reddit_homosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_homosexual_collocation_insults2 = find_list_of_words_in_df(reddit_homosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_homosexual_collocation_insults = pd.concat([reddit_homosexual_collocation_insults1,reddit_homosexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a36279c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homosexual insultive collocation average PMI: 8.902458475680914\n"
     ]
    }
   ],
   "source": [
    "print(\"homosexual insultive collocation average PMI:\",np.mean(reddit_homosexual_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3c98f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found queer\n",
      "terms found queer\n"
     ]
    }
   ],
   "source": [
    "reddit_queer_collocation = pd.read_csv(collocation_folder+\"/reddit_queer_collocation.csv\")\n",
    "reddit_queer_collocation = reddit_queer_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_queer_collocation_insults1 = find_list_of_words_in_df(reddit_queer_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_queer_collocation_insults2 = find_list_of_words_in_df(reddit_queer_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_queer_collocation_insults = pd.concat([reddit_queer_collocation_insults1,reddit_queer_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb05d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queer insultive collocation average PMI: 9.617744034032869\n"
     ]
    }
   ],
   "source": [
    "print(\"queer insultive collocation average PMI:\",np.mean(reddit_queer_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fa317be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found ass\n",
      "terms found cum\n",
      "terms found ejaculate\n",
      "terms found ejaculation\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found pron\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_female_collocation = pd.read_csv(collocation_folder+\"/reddit_female_collocation.csv\")\n",
    "reddit_female_collocation = reddit_female_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_female_collocation_insults1 = find_list_of_words_in_df(reddit_female_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_female_collocation_insults2 = find_list_of_words_in_df(reddit_female_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_female_collocation_insults = pd.concat([reddit_female_collocation_insults1,reddit_female_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dc5ff7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female insultive collocation average PMI: 8.3855921101628\n"
     ]
    }
   ],
   "source": [
    "print(\"female insultive collocation average PMI:\",np.mean(reddit_female_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c4f77f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found balls\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found ass\n",
      "terms found cock\n",
      "terms found cocks\n",
      "terms found dick\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found hore\n",
      "terms found shi\n",
      "terms found whore\n"
     ]
    }
   ],
   "source": [
    "reddit_black_collocation = pd.read_csv(collocation_folder+\"/reddit_black_collocation.csv\")\n",
    "reddit_black_collocation = reddit_black_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_black_collocation_insults1 = find_list_of_words_in_df(reddit_black_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_black_collocation_insults2 = find_list_of_words_in_df(reddit_black_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_black_collocation_insults = pd.concat([reddit_black_collocation_insults1,reddit_black_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4955a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black insultive collocation average PMI: 6.223302893940736\n"
     ]
    }
   ],
   "source": [
    "print(\"black insultive collocation average PMI:\",np.mean(reddit_black_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a22bb763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_middle_eastern_collocation = pd.read_csv(collocation_folder+\"/reddit_middle-eastern_collocation.csv\")\n",
    "reddit_middle_eastern_collocation = reddit_middle_eastern_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_middle_eastern_collocation_insults1 = find_list_of_words_in_df(reddit_middle_eastern_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_middle_eastern_collocation_insults2 = find_list_of_words_in_df(reddit_middle_eastern_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_middle_eastern_collocation_insults = pd.concat([reddit_middle_eastern_collocation_insults1,reddit_middle_eastern_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92f787a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found queer\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_indian_collocation = pd.read_csv(collocation_folder+\"/reddit_indian_collocation.csv\")\n",
    "reddit_indian_collocation = reddit_indian_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_indian_collocation_insults1 = find_list_of_words_in_df(reddit_indian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_indian_collocation_insults2 = find_list_of_words_in_df(reddit_indian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_indian_collocation_insults = pd.concat([reddit_indian_collocation_insults1,reddit_indian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "77ec7607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian insultive collocation average PMI: 9.53157366650878\n"
     ]
    }
   ],
   "source": [
    "print(\"indian insultive collocation average PMI:\",np.mean(reddit_indian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "988a2aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_non_binary_collocation = pd.read_csv(collocation_folder+\"/reddit_non-binary_collocation.csv\")\n",
    "reddit_non_binary_collocation = reddit_non_binary_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_non_binary_collocation_insults1 = find_list_of_words_in_df(reddit_non_binary_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_non_binary_collocation_insults2 = find_list_of_words_in_df(reddit_non_binary_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_non_binary_collocation_insults = pd.concat([reddit_non_binary_collocation_insults1,reddit_non_binary_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48806692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
