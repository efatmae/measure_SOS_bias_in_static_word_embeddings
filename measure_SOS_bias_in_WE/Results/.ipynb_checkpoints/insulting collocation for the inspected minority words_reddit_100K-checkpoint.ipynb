{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8972cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac428c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_of_words_in_df(df, slur_list, text_col):\n",
    "  ps_in_hateEval = []\n",
    "  for i in slur_list: \n",
    "    if  df[text_col].str.contains(i).any() == True:\n",
    "      print(\"terms found \"+ i)  \n",
    "      ps_mid = df[df[text_col].str.contains(i)]\n",
    "      ps_in_hateEval.append(ps_mid)\n",
    "      \n",
    "  if len(ps_in_hateEval)>0:\n",
    "      ps_in_hateEval_df = pd.concat(ps_in_hateEval)\n",
    "      return ps_in_hateEval_df\n",
    "  else:\n",
    "        print (\"Nothing found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eda276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f931e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "profane_words = open(data_folder+\"swear_words.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fa44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocation_folder = \"./collocation_results/minority/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7690af08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reddit_transgender_collocation.csv',\n",
       " 'reddit_lgtbq_collocation.csv',\n",
       " 'reddit_lesbian_collocation.csv',\n",
       " 'reddit_mother_collocation.csv',\n",
       " 'reddit_wife_collocation.csv',\n",
       " 'reddit_trans_collocation.csv',\n",
       " 'reddit_latino_collocation.csv',\n",
       " 'reddit_daughter_collocation.csv',\n",
       " 'reddit_bisexual_collocation.csv',\n",
       " 'reddit_negro_collocation.csv',\n",
       " 'reddit_arab_collocation.csv',\n",
       " 'reddit_sister_collocation.csv',\n",
       " 'reddit_woman_collocation.csv',\n",
       " 'reddit_gay_collocation.csv',\n",
       " 'reddit_african_collocation.csv',\n",
       " 'reddit_mexican_collocation.csv',\n",
       " 'reddit_lgtb_collocation.csv',\n",
       " 'reddit_whore_collocation.csv',\n",
       " 'reddit_girl_collocation.csv',\n",
       " 'reddit_asian_collocation.csv',\n",
       " 'reddit_hispanic_collocation.csv',\n",
       " 'brown_corpus_girl_collocation.csv',\n",
       " '.~lock.reddit_african_collocation.csv#',\n",
       " 'reddit_homosexual_collocation.csv',\n",
       " 'reddit_queer_collocation.csv',\n",
       " 'reddit_female_collocation.csv',\n",
       " 'reddit_black_collocation.csv',\n",
       " 'reddit_middle-eastern_collocation.csv',\n",
       " 'reddit_indian_collocation.csv',\n",
       " 'reddit_non-binary_collocation.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(collocation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "130d2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_transgender_collocation = pd.read_csv(collocation_folder+\"/reddit_transgender_collocation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f942de9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_transgender_collocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae07aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'word1', 'word2', 'PMI'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_transgender_collocation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "899fce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_transgender_collocation_insults = find_list_of_words_in_df(reddit_transgender_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "300bf023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_lgtbq_collocation = pd.read_csv(collocation_folder+\"/reddit_lgtbq_collocation.csv\")\n",
    "reddit_lgtbq_collocation_insults1 = find_list_of_words_in_df(reddit_lgtbq_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lgtbq_collocation_insults2 = find_list_of_words_in_df(reddit_lgtbq_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ba6307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bitch\n",
      "terms found sex\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_lesbian_collocation = pd.read_csv(collocation_folder+\"/reddit_lesbian_collocation.csv\")\n",
    "reddit_lesbian_collocation_insults1 = find_list_of_words_in_df(reddit_lesbian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lesbian_collocation_insults2 = find_list_of_words_in_df(reddit_lesbian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_lesbian_collocation_insults = pd.concat([reddit_lesbian_collocation_insults1,reddit_lesbian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd7a55d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesbian insultive collocation average PMI: 9.446476248839735\n"
     ]
    }
   ],
   "source": [
    "print(\"lesbian insultive collocation average PMI:\",np.mean(reddit_lesbian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1d8e751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bad\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found retard\n",
      "terms found fuck\n",
      "terms found fucker\n",
      "terms found fuckers\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found kill\n",
      "terms found shi\n"
     ]
    }
   ],
   "source": [
    "reddit_mother_collocation = pd.read_csv(collocation_folder+\"/reddit_mother_collocation.csv\")\n",
    "reddit_mother_collocation_insults1 = find_list_of_words_in_df(reddit_mother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_mother_collocation_insults2 = find_list_of_words_in_df(reddit_mother_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_mother_collocation_insults = pd.concat([reddit_mother_collocation_insults1,reddit_mother_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d96c6633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother insultive collocation average PMI: 6.154385904068221\n"
     ]
    }
   ],
   "source": [
    "print(\"mother insultive collocation average PMI:\",np.mean(reddit_mother_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4262f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found dyke\n",
      "terms found aps\n",
      "terms found horny\n",
      "terms found aps\n",
      "terms found ass\n",
      "terms found bad\n",
      "terms found hate\n"
     ]
    }
   ],
   "source": [
    "reddit_wife_collocation = pd.read_csv(collocation_folder+\"/reddit_wife_collocation.csv\")\n",
    "reddit_wife_collocation_insults1 = find_list_of_words_in_df(reddit_wife_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_wife_collocation_insults2 = find_list_of_words_in_df(reddit_wife_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_wife_collocation_insults = pd.concat([reddit_wife_collocation_insults1,reddit_wife_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4d0eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wife insultive collocation average PMI: 7.46867475604032\n"
     ]
    }
   ],
   "source": [
    "print(\"wife insultive collocation average PMI:\",np.mean(reddit_wife_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf0ddcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found sex\n",
      "terms found fat\n"
     ]
    }
   ],
   "source": [
    "reddit_trans_collocation = pd.read_csv(collocation_folder+\"/reddit_trans_collocation.csv\")\n",
    "reddit_trans_collocation_insults1 = find_list_of_words_in_df(reddit_trans_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_trans_collocation_insults2 = find_list_of_words_in_df(reddit_trans_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "reddit_trans_collocation_insults = pd.concat([reddit_trans_collocation_insults1,reddit_trans_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb5ee4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans insultive collocation average PMI: 12.25952561318715\n"
     ]
    }
   ],
   "source": [
    "print(\"trans insultive collocation average PMI:\",np.mean(reddit_trans_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "899690c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_latino_collocation = pd.read_csv(collocation_folder+\"/reddit_latino_collocation.csv\")\n",
    "reddit_latino_collocation_insults1 = find_list_of_words_in_df(reddit_latino_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_latino_collocation_insults2 = find_list_of_words_in_df(reddit_latino_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_latino_collocation_insults = pd.concat([reddit_latino_collocation_insults1,reddit_latino_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7b21876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found fat\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_daughter_collocation = pd.read_csv(collocation_folder+\"/reddit_daughter_collocation.csv\")\n",
    "reddit_daughter_collocation_insults1 = find_list_of_words_in_df(reddit_daughter_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_daughter_collocation_insults2 = find_list_of_words_in_df(reddit_daughter_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_latino_collocation_insults = pd.concat([reddit_latino_collocation_insults1,reddit_latino_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f25af1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daughter insultive collocation average PMI: 5.8679615710266395\n"
     ]
    }
   ],
   "source": [
    "print(\"daughter insultive collocation average PMI:\",np.mean(reddit_daughter_collocation_insults1.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ada2ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found sex\n",
      "terms found sex\n"
     ]
    }
   ],
   "source": [
    "reddit_bisexual_collocation = pd.read_csv(collocation_folder+\"/reddit_bisexual_collocation.csv\")\n",
    "reddit_bisexual_collocation_insults1 = find_list_of_words_in_df(reddit_bisexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_bisexual_collocation_insults2 = find_list_of_words_in_df(reddit_bisexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_bisexual_collocation_insults = pd.concat([reddit_bisexual_collocation_insults1,reddit_bisexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aaafe933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bisexual insultive collocation average PMI: 9.756275755080061\n"
     ]
    }
   ],
   "source": [
    "print(\"bisexual insultive collocation average PMI:\",np.mean(reddit_bisexual_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f63fbb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found kill\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_negro_collocation = pd.read_csv(collocation_folder+\"/reddit_negro_collocation.csv\")\n",
    "reddit_negro_collocation_insults1 = find_list_of_words_in_df(reddit_negro_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_negro_collocation_insults2 = find_list_of_words_in_df(reddit_negro_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_negro_collocation_insults = pd.concat([reddit_negro_collocation_insults1,reddit_negro_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8b9c0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negro insultive collocation average PMI: 10.363294336641166\n"
     ]
    }
   ],
   "source": [
    "print(\"negro insultive collocation average PMI:\",np.mean(reddit_negro_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26d2ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_arab_collocation = pd.read_csv(collocation_folder+\"/reddit_arab_collocation.csv\")\n",
    "reddit_arab_collocation_insults1 = find_list_of_words_in_df(reddit_arab_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_arab_collocation_insults2 = find_list_of_words_in_df(reddit_arab_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_arab_collocation_insults = pd.concat([reddit_arab_collocation_insults1,reddit_arab_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a65d1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arab insultive collocation average PMI: 11.1632030742159\n"
     ]
    }
   ],
   "source": [
    "print(\"arab insultive collocation average PMI:\",np.mean(reddit_arab_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62bbc535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found aps\n",
      "terms found aps\n"
     ]
    }
   ],
   "source": [
    "reddit_sister_collocation = pd.read_csv(collocation_folder+\"/reddit_sister_collocation.csv\")\n",
    "reddit_sister_collocation_insults1 = find_list_of_words_in_df(reddit_sister_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_sister_collocation_insults2 = find_list_of_words_in_df(reddit_sister_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_sister_collocation_insults = pd.concat([reddit_sister_collocation_insults1,reddit_sister_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "499e3260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sister insultive collocation average PMI: 14.087254220982608\n"
     ]
    }
   ],
   "source": [
    "print(\"sister insultive collocation average PMI:\",np.mean(reddit_sister_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64ec3070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bitch\n",
      "terms found boob\n",
      "terms found butt\n",
      "terms found jap\n",
      "terms found sex\n",
      "terms found ugly\n",
      "terms found cum\n",
      "terms found hate\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found suck\n"
     ]
    }
   ],
   "source": [
    "reddit_woman_collocation = pd.read_csv(collocation_folder+\"/reddit_woman_collocation.csv\")\n",
    "reddit_woman_collocation_insults1 = find_list_of_words_in_df(reddit_woman_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_woman_collocation_insults2 = find_list_of_words_in_df(reddit_woman_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_woman_collocation_insults = pd.concat([reddit_woman_collocation_insults1,reddit_woman_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c5e008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman insultive collocation average PMI: 6.121113306028144\n"
     ]
    }
   ],
   "source": [
    "print(\"woman insultive collocation average PMI:\",np.mean(reddit_woman_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32891638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found bitch\n",
      "terms found dumb\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found idiot\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found tit\n",
      "terms found butt\n",
      "terms found fag\n",
      "terms found fags\n",
      "terms found jerk\n",
      "terms found mean\n",
      "terms found penis\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_gay_collocation = pd.read_csv(collocation_folder+\"/reddit_gay_collocation.csv\")\n",
    "reddit_gay_collocation_insults1 = find_list_of_words_in_df(reddit_gay_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_gay_collocation_insults2 = find_list_of_words_in_df(reddit_gay_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_gay_collocation_insults = pd.concat([reddit_gay_collocation_insults1,reddit_gay_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b3f4e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gay insultive collocation average PMI: 6.322586868064068\n"
     ]
    }
   ],
   "source": [
    "print(\"gay insultive collocation average PMI:\",np.mean(reddit_gay_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aeb7ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_african_collocation = pd.read_csv(collocation_folder+\"/reddit_african_collocation.csv\")\n",
    "reddit_african_collocation_insults1 = find_list_of_words_in_df(reddit_african_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_african_collocation_insults2 = find_list_of_words_in_df(reddit_african_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_african_collocation_insults = pd.concat([reddit_african_collocation_insults1,reddit_african_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "408b34d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "african insultive collocation average PMI: 11.8257619799572\n"
     ]
    }
   ],
   "source": [
    "print(\"african insultive collocation average PMI:\",np.mean(reddit_african_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54f119f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found cum\n",
      "terms found fat\n",
      "terms found shi\n",
      "terms found ass\n",
      "terms found cok\n"
     ]
    }
   ],
   "source": [
    "reddit_mexican_collocation = pd.read_csv(collocation_folder+\"/reddit_mexican_collocation.csv\")\n",
    "reddit_mexican_collocation_insults1 = find_list_of_words_in_df(reddit_mexican_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_mexican_collocation_insults2 = find_list_of_words_in_df(reddit_mexican_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_mexican_collocation_insults = pd.concat([reddit_mexican_collocation_insults1,reddit_mexican_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b12d094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mexican insultive collocation average PMI: 8.903277108008933\n"
     ]
    }
   ],
   "source": [
    "print(\"mexican insultive collocation average PMI:\",np.mean(reddit_mexican_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2be231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_lgtb_collocation = pd.read_csv(collocation_folder+\"/reddit_lgtb_collocation.csv\")\n",
    "reddit_lgtb_collocation_insults1 = find_list_of_words_in_df(reddit_lgtb_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_lgtb_collocation_insults2 = find_list_of_words_in_df(reddit_lgtb_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_lgtb_collocation_insults = pd.concat([reddit_lgtb_collocation_insults1,reddit_lgtb_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93e66071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found dumb\n",
      "terms found fat\n",
      "terms found fuck\n",
      "terms found fuckin\n",
      "terms found fucking\n",
      "terms found hate\n",
      "terms found hell\n",
      "terms found jap\n",
      "terms found sex\n",
      "terms found stupid\n",
      "terms found ugly\n",
      "terms found boob\n",
      "terms found boobs\n",
      "terms found hate\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitting\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_girl_collocation = pd.read_csv(collocation_folder+\"/reddit_girl_collocation.csv\")\n",
    "reddit_girl_collocation_insults1 = find_list_of_words_in_df(reddit_girl_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_girl_collocation_insults2 = find_list_of_words_in_df(reddit_girl_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_girl_collocation_insults = pd.concat([reddit_girl_collocation_insults1,reddit_girl_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89ae4489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl insultive collocation average PMI: 3.7360721742242604\n"
     ]
    }
   ],
   "source": [
    "print(\"girl insultive collocation average PMI:\",np.mean(reddit_girl_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "478167b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found homo\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found bitch\n"
     ]
    }
   ],
   "source": [
    "reddit_asian_collocation = pd.read_csv(collocation_folder+\"/reddit_asian_collocation.csv\")\n",
    "reddit_asian_collocation = reddit_asian_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_asian_collocation_insults1 = find_list_of_words_in_df(reddit_asian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_asian_collocation_insults2 = find_list_of_words_in_df(reddit_asian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_asian_collocation_insults = pd.concat([reddit_asian_collocation_insults1,reddit_asian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "056155e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asian insultive collocation average PMI: 7.053557133484275\n"
     ]
    }
   ],
   "source": [
    "print(\"asian insultive collocation average PMI:\",np.mean(reddit_asian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "896fd403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_hispanic_collocation = pd.read_csv(collocation_folder+\"/reddit_hispanic_collocation.csv\")\n",
    "reddit_hispanic_collocation = reddit_hispanic_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_hispanic_collocation_insults1 = find_list_of_words_in_df(reddit_hispanic_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_hispanic_collocation_insults2 = find_list_of_words_in_df(reddit_hispanic_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_hispanic_collocation_insults = pd.concat([reddit_hispanic_collocation_insults1,reddit_hispanic_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "145d2a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found homo\n",
      "terms found sex\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found sex\n",
      "terms found shi\n"
     ]
    }
   ],
   "source": [
    "reddit_homosexual_collocation = pd.read_csv(collocation_folder+\"/reddit_homosexual_collocation.csv\")\n",
    "reddit_homosexual_collocation = reddit_homosexual_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_homosexual_collocation_insults1 = find_list_of_words_in_df(reddit_homosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_homosexual_collocation_insults2 = find_list_of_words_in_df(reddit_homosexual_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_homosexual_collocation_insults = pd.concat([reddit_homosexual_collocation_insults1,reddit_homosexual_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "596277ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homosexual insultive collocation average PMI: 8.902458475680914\n"
     ]
    }
   ],
   "source": [
    "print(\"homosexual insultive collocation average PMI:\",np.mean(reddit_homosexual_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e9e7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found queer\n",
      "terms found queer\n"
     ]
    }
   ],
   "source": [
    "reddit_queer_collocation = pd.read_csv(collocation_folder+\"/reddit_queer_collocation.csv\")\n",
    "reddit_queer_collocation = reddit_queer_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_queer_collocation_insults1 = find_list_of_words_in_df(reddit_queer_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_queer_collocation_insults2 = find_list_of_words_in_df(reddit_queer_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_queer_collocation_insults = pd.concat([reddit_queer_collocation_insults1,reddit_queer_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28225f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queer insultive collocation average PMI: 9.617744034032869\n"
     ]
    }
   ],
   "source": [
    "print(\"queer insultive collocation average PMI:\",np.mean(reddit_queer_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b15647c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found bad\n",
      "terms found shi\n",
      "terms found shit\n",
      "terms found shitty\n",
      "terms found ass\n",
      "terms found cum\n",
      "terms found ejaculate\n",
      "terms found ejaculation\n",
      "terms found homo\n",
      "terms found mean\n",
      "terms found pron\n",
      "terms found sex\n",
      "terms found shi\n",
      "terms found tit\n"
     ]
    }
   ],
   "source": [
    "reddit_female_collocation = pd.read_csv(collocation_folder+\"/reddit_female_collocation.csv\")\n",
    "reddit_female_collocation = reddit_female_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_female_collocation_insults1 = find_list_of_words_in_df(reddit_female_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_female_collocation_insults2 = find_list_of_words_in_df(reddit_female_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_female_collocation_insults = pd.concat([reddit_female_collocation_insults1,reddit_female_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7343df81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female insultive collocation average PMI: 8.3855921101628\n"
     ]
    }
   ],
   "source": [
    "print(\"female insultive collocation average PMI:\",np.mean(reddit_female_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8108e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found balls\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found kill\n",
      "terms found mean\n",
      "terms found ass\n",
      "terms found cock\n",
      "terms found cocks\n",
      "terms found dick\n",
      "terms found fat\n",
      "terms found hate\n",
      "terms found hore\n",
      "terms found shi\n",
      "terms found whore\n"
     ]
    }
   ],
   "source": [
    "reddit_black_collocation = pd.read_csv(collocation_folder+\"/reddit_black_collocation.csv\")\n",
    "reddit_black_collocation = reddit_black_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_black_collocation_insults1 = find_list_of_words_in_df(reddit_black_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_black_collocation_insults2 = find_list_of_words_in_df(reddit_black_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_black_collocation_insults = pd.concat([reddit_black_collocation_insults1,reddit_black_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b895bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black insultive collocation average PMI: 6.223302893940736\n"
     ]
    }
   ],
   "source": [
    "print(\"black insultive collocation average PMI:\",np.mean(reddit_black_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0bd5fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_middle_eastern_collocation = pd.read_csv(collocation_folder+\"/reddit_middle-eastern_collocation.csv\")\n",
    "reddit_middle_eastern_collocation = reddit_middle_eastern_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_middle_eastern_collocation_insults1 = find_list_of_words_in_df(reddit_middle_eastern_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_middle_eastern_collocation_insults2 = find_list_of_words_in_df(reddit_middle_eastern_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_middle_eastern_collocation_insults = pd.concat([reddit_middle_eastern_collocation_insults1,reddit_middle_eastern_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bbd838e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms found ass\n",
      "terms found queer\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_indian_collocation = pd.read_csv(collocation_folder+\"/reddit_indian_collocation.csv\")\n",
    "reddit_indian_collocation = reddit_indian_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_indian_collocation_insults1 = find_list_of_words_in_df(reddit_indian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_indian_collocation_insults2 = find_list_of_words_in_df(reddit_indian_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "reddit_indian_collocation_insults = pd.concat([reddit_indian_collocation_insults1,reddit_indian_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "169637b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian insultive collocation average PMI: 9.53157366650878\n"
     ]
    }
   ],
   "source": [
    "print(\"indian insultive collocation average PMI:\",np.mean(reddit_indian_collocation_insults.PMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9a798d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing found\n",
      "Nothing found\n"
     ]
    }
   ],
   "source": [
    "reddit_non_binary_collocation = pd.read_csv(collocation_folder+\"/reddit_non-binary_collocation.csv\")\n",
    "reddit_non_binary_collocation = reddit_non_binary_collocation.dropna(subset=[\"word1\",'word2'])\n",
    "reddit_non_binary_collocation_insults1 = find_list_of_words_in_df(reddit_non_binary_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word1\")\n",
    "reddit_non_binary_collocation_insults2 = find_list_of_words_in_df(reddit_non_binary_collocation,\n",
    "                                                                 profane_words,\n",
    "                                                                 \"word2\")\n",
    "\n",
    "#reddit_non_binary_collocation_insults = pd.concat([reddit_non_binary_collocation_insults1,reddit_non_binary_collocation_insults2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836b10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
